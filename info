MemexQA dataset

fetaures:
1) Personal Photos
2) Sequence input
3) Specific goal-driven
4) Evidential Photos
5) Personal media collection
6) Metadata time & GPS


Dataset Content

memexqa_dataset_v1.1/
		├── album_info.json   # album data: https://memexqa.cs.cmu.edu/memexqa_dataset_v1.1/album_info.json
		├── glove.6B.100d.txt # word vectors for baselines:  http://nlp.stanford.edu/data/glove.6B.zip
		├── shown_photos.tgz (7.5GB)  # all photos: https://memexqa.cs.cmu.edu/memexqa_dataset_v1.1/shown_photos.tgz
		├── qas.json # QA data: https://memexqa.cs.cmu.edu/memexqa_dataset_v1.1/qas.json
		└── test_question.ids # testset Id: https://memexqa.cs.cmu.edu/memexqa_dataset_v1.1/test_question.ids

Preprocessing

outputs:

*_data.p
    tokenized question
    answer
    pointer to album

*_shared.p
    wordcounter
    album

*_data.p/
		├── 'q':q // 'list', containing question in word tokenized form
		├── 'cq':cq // 'list', containing question in char tokenized form
        ├── 'y':y // 'list', containing answer in word tokenized form
        ├── 'cy':cy // 'list', containing answer in char tokenized form
        ├── 'yidx':yidx // 'list', containing index of answer in multiple choice
        ├── 'aid':aid // 'list', containing index of albumID of albums used
        ├── 'idxs':idxs // 'list', containing index
        ├── 'cs':cs // 'list', containing multiple choice for question in word tokenized form
		└── 'css':css // 'list', containing multiple choice for question in char tokenized form

*_shared.p/
        ├── 'albums':albums // 'dict', containing album info corresponding to albumID as its key 
        ├── 'pid2feat':pid2feat // 'dict', containing photo feat corresponding to photoID as its key
        ├── 'wordCounter':wordCounter // 'dict', containing word count corresponding to word as its key
        ├── 'charCounter':charCounter // 'dict', containing char count corresponding to char as its key
		└── 'word2vec':word2vec // 'dict', containing vector embedding corresponding to word as its key



